
@article{cutler_archetypal_1994,
	title = {Archetypal {Analysis}},
	volume = {36},
	issn = {0040-1706},
	url = {https://www.jstor.org/stable/1269949},
	doi = {10.2307/1269949},
	abstract = {Archetypal analysis represents each individual in a data set as a mixture of individuals of pure type or archetypes. The archetypes themselves are restricted to being mixtures of the individuals in the data set. Archetypes are selected by minimizing the squared error in representing each individual as a mixture of archetypes. The usefulness of archetypal analysis is illustrated on several data sets. Computing the archetypes is a nonlinear least squares problem, which is solved using an alternating minimizing algorithm.},
	number = {4},
	urldate = {2024-04-23},
	journal = {Technometrics},
	author = {Cutler, Adele and Breiman, Leo},
	year = {1994},
	keywords = {archetypal analysis},
	pages = {338--347},
}

@article{alcacer_biarchetype_2024,
	title = {Biarchetype {Analysis}: {Simultaneous} {Learning} of {Observations} and {Features} {Based} on {Extremes}},
	issn = {1939-3539},
	shorttitle = {Biarchetype {Analysis}},
	url = {https://ieeexplore.ieee.org/abstract/document/10530052},
	doi = {10.1109/TPAMI.2024.3400730},
	abstract = {We introduce a novel exploratory technique, termed biarchetype analysis, which extends archetype analysis to simultaneously identify archetypes of both observations and features. This innovative unsupervised machine learning tool aims to represent observations and features through instances of pure types, or biarchetypes, which are easily interpretable as they embody mixtures of observations and features. Furthermore, the observations and features are expressed as mixtures of the biarchetypes, which makes the structure of the data easier to understand. We propose an algorithm to solve biarchetype analysis. Although clustering is not the primary aim of this technique, biarchetype analysis is demonstrated to offer significant advantages over biclustering methods, particularly in terms of interpretability. This is attributed to biarchetypes being extreme instances, in contrast to the centroids produced by biclustering, which inherently enhances human comprehension. The application of biarchetype analysis across various machine learning challenges underscores its value, and both the source code and examples are readily accessible in R and Python at https://github.com/aleixalcacer/JA-BIAA.},
	urldate = {2024-05-29},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Alcacer, Aleix and Epifanio, Irene and Gual-Arnau, Ximo},
	year = {2024},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Archetype analysis, biclustering, Data analysis, Elbow, Gene expression, Proposals, prototype, Prototypes, Sociology, Sports, unsupervised learning},
	pages = {1--12},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\aalcacer\\Zotero\\storage\\6BJ2GVXZ\\10530052.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\aalcacer\\Zotero\\storage\\7QUBB22S\\Alcacer et al. - 2024 - Biarchetype Analysis Simultaneous Learning of Obs.pdf:application/pdf},
}

@article{morup_archetypal_2012,
	series = {Special {Issue} on {Machine} {Learning} for {Signal} {Processing} 2010},
	title = {Archetypal analysis for machine learning and data mining},
	volume = {80},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231211006060},
	doi = {10.1016/j.neucom.2011.06.033},
	abstract = {Archetypal analysis (aa) proposed by Cutler and Breiman (1994) [7] estimates the principal convex hull (pch) of a data set. As such aa favors features that constitute representative ‘corners’ of the data, i.e., distinct aspects or archetypes. We currently show that aa enjoys the interpretability of clustering – without being limited to hard assignment and the uniqueness of svd – without being limited to orthogonal representations. In order to do large scale aa, we derive an efficient algorithm based on projected gradient as well as an initialization procedure we denote FurthestSum that is inspired by the FurthestFirst approach widely used for k-means (Hochbaum and Shmoys, 1985 [14]). We generalize the aa procedure to kernel-aa in order to extract the principal convex hull in potential infinite Hilbert spaces and derive a relaxation of aa when the archetypes cannot be represented as convex combinations of the observed data. We further demonstrate that the aa model is relevant for feature extraction and dimensionality reduction for a large variety of machine learning problems taken from computer vision, neuroimaging, chemistry, text mining and collaborative filtering leading to highly interpretable representations of the dynamics in the data. Matlab code for the derived algorithms is available for download from www.mortenmorup.dk.},
	urldate = {2024-05-29},
	journal = {Neurocomputing},
	author = {Mørup, Morten and Hansen, Lars Kai},
	month = mar,
	year = {2012},
	keywords = {Archetypal analysis, Clustering, FurthestFirst, FurthestSum, Kernel methods, Non-negative matrix factorization, Principal convex hull},
	pages = {54--63},
	file = {ScienceDirect Snapshot:C\:\\Users\\aalcacer\\Zotero\\storage\\X482FVY4\\S0925231211006060.html:text/html},
}

@misc{mair_archetypal_2024,
	title = {Archetypal {Analysis}++: {Rethinking} the {Initialization} {Strategy}},
	shorttitle = {Archetypal {Analysis}++},
	url = {http://arxiv.org/abs/2301.13748},
	doi = {10.48550/arXiv.2301.13748},
	abstract = {Archetypal analysis is a matrix factorization method with convexity constraints. Due to local minima, a good initialization is essential, but frequently used initialization methods yield either sub-optimal starting points or are prone to get stuck in poor local minima. In this paper, we propose archetypal analysis++ (AA++), a probabilistic initialization strategy for archetypal analysis that sequentially samples points based on their influence on the objective function, similar to \$k\$-means++. In fact, we argue that \$k\$-means++ already approximates the proposed initialization method. Furthermore, we suggest to adapt an efficient Monte Carlo approximation of \$k\$-means++ to AA++. In an extensive empirical evaluation of 15 real-world data sets of varying sizes and dimensionalities and considering two pre-processing strategies, we show that AA++ almost always outperforms all baselines, including the most frequently used ones.},
	urldate = {2024-07-03},
	publisher = {arXiv},
	author = {Mair, Sebastian and Sjölund, Jens},
	month = may,
	year = {2024},
	note = {arXiv:2301.13748 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\aalcacer\\Zotero\\storage\\ITADM4K2\\Mair and Sjölund - 2024 - Archetypal Analysis++ Rethinking the Initializati.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\aalcacer\\Zotero\\storage\\ZB2RSSDB\\2301.html:text/html},
}

@article{gonzalez_clustering_1985,
	title = {Clustering to minimize the maximum intercluster distance},
	volume = {38},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/0304397585902245},
	doi = {10.1016/0304-3975(85)90224-5},
	abstract = {The problem of clustering a set of points so as to minimize the maximum intercluster distance is studied. An O(kn) approximation algorithm, where n is the number of points and k is the number of clusters, that guarantees solutions with an objective function value within two times the optimal solution value is presented. This approximation algorithm succeeds as long as the set of points satisfies the triangular inequality. We also show that our approximation algorithm is best possible, with respect to the approximation bound, if P ≠ NP.},
	urldate = {2024-07-03},
	journal = {Theoretical Computer Science},
	author = {Gonzalez, Teofilo F.},
	month = jan,
	year = {1985},
	keywords = {Algorithms, approximation algorithms, clustering, minimizing the maximum intercluster distance, NP-completeness},
	pages = {293--306},
	file = {ScienceDirect Snapshot:C\:\\Users\\aalcacer\\Zotero\\storage\\CHN5DS65\\0304397585902245.html:text/html},
}
